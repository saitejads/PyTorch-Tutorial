{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Basics\n",
    "- GPU Version of Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python's variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "a = 5\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch's Integer type Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 5\n",
      "[torch.IntTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tor_a = torch.IntTensor([5])\n",
    "\n",
    "print(tor_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch's Float type Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 5\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tor_b = torch.FloatTensor([5.])\n",
    "\n",
    "print(tor_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100 200 300]\n",
      " [700 800 900]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "np_arr = np.array([[100,200,300],[700,800,900]])\n",
    "\n",
    "print(np_arr)\n",
    "\n",
    "print(type(np_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 100  200  300\n",
      " 700  800  900\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "<class 'torch.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "tor_arr = torch.Tensor([[100,200,300],[700,800,900]])\n",
    "\n",
    "print(tor_arr)\n",
    "\n",
    "print(type(tor_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy Random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39701946 0.03057078]\n",
      " [0.81256814 0.07725723]\n",
      " [0.04435339 0.17788542]\n",
      " [0.73828156 0.14481408]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_rand = np.random.random((4,2))\n",
    "\n",
    "print(np_rand)\n",
    "\n",
    "type(np_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Torch Random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.8093  0.4249\n",
      " 0.0739  0.6678\n",
      " 0.6014  0.1661\n",
      " 0.3960  0.1055\n",
      "[torch.FloatTensor of size 4x2]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.FloatTensor"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tor_rand = torch.rand((4,2))\n",
    "\n",
    "print(tor_rand)\n",
    "\n",
    "type(tor_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy Concatenate of arrays, along axis 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58722706, 0.82431861],\n",
       "       [0.7075532 , 0.87094527],\n",
       "       [0.90205503, 0.39062058],\n",
       "       [0.81207083, 0.40027266],\n",
       "       [0.58722706, 0.82431861],\n",
       "       [0.7075532 , 0.87094527],\n",
       "       [0.90205503, 0.39062058],\n",
       "       [0.81207083, 0.40027266]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((np_rand,np_rand),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy Concatenate of arrays, along axis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58722706, 0.82431861, 0.58722706, 0.82431861],\n",
       "       [0.7075532 , 0.87094527, 0.7075532 , 0.87094527],\n",
       "       [0.90205503, 0.39062058, 0.90205503, 0.39062058],\n",
       "       [0.81207083, 0.40027266, 0.81207083, 0.40027266]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((np_rand,np_rand),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch Concatenation of Tensors, along axis 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.8093  0.4249\n",
       " 0.0739  0.6678\n",
       " 0.6014  0.1661\n",
       " 0.3960  0.1055\n",
       " 0.8093  0.4249\n",
       " 0.0739  0.6678\n",
       " 0.6014  0.1661\n",
       " 0.3960  0.1055\n",
       "[torch.FloatTensor of size 8x2]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((tor_rand,tor_rand),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch Concatenation of Tensors, along axis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.8093  0.4249  0.8093  0.4249\n",
       " 0.0739  0.6678  0.0739  0.6678\n",
       " 0.6014  0.1661  0.6014  0.1661\n",
       " 0.3960  0.1055  0.3960  0.1055\n",
       "[torch.FloatTensor of size 4x4]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((tor_rand,tor_rand),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy Arrays Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE BEFORE :  (4, 2)\n",
      "SHAPE AFTER : (2, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"SHAPE BEFORE : \",np_rand.shape)\n",
    "\n",
    "np_rand = np_rand.reshape((2,4))\n",
    "\n",
    "print(\"SHAPE AFTER :\",np_rand.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors reshape(view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE BEFORE :  torch.Size([4, 2])\n",
      "SHAPE AFTER : torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"SHAPE BEFORE : \",tor_rand.shape)\n",
    "\n",
    "tor_rand = tor_rand.view((2,4))\n",
    "\n",
    "print(\"SHAPE AFTER :\",tor_rand.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Array to Tensor conversion. \n",
    "- torch.from_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.3970  0.0306\n",
      " 0.8126  0.0773\n",
      " 0.0444  0.1779\n",
      " 0.7383  0.1448\n",
      "[torch.DoubleTensor of size 4x2]\n",
      "\n",
      "<class 'torch.DoubleTensor'>\n"
     ]
    }
   ],
   "source": [
    "print(torch.from_numpy(np_rand))\n",
    "\n",
    "print(type(torch.from_numpy(np_rand)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor to Numpy array Conversion\n",
    "- .numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8093433  0.4249366  0.07388103 0.667755  ]\n",
      " [0.60139036 0.16605508 0.39601856 0.10545868]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(tor_rand.numpy())\n",
    "\n",
    "print(type(tor_rand.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables allows us to calculate the gradients through back propagation.\n",
    "- requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Variable(torch.Tensor([10]), requires_grad=True)\n",
    "x = Variable(torch.Tensor([5]), requires_grad=True)\n",
    "b = Variable(torch.Tensor([3]), requires_grad=True)\n",
    "c = Variable(torch.Tensor([2]), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 10\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 5\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(x)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's make some quadratic equation\n",
    "- y = ax2 + bx + c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = a * (x*x) + b * x + c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There will not be any gradients assigned,cuz we havent done backpropagation yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)\n",
    "print(b.grad)\n",
    "print(m.grad)\n",
    "print(c.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### x.grad means differentiating the equation wrt to x.\n",
    "- dy/dx = 2ax + b\n",
    "- Subsititute values of a,x and b, you get 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 103\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.grad means differentiating the equation wrt to a.\n",
    "- dy/da = x2\n",
    "- Subsititute value of x, you get 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 25\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.grad means differentiating the equation wrt to x.\n",
    "- dy/db = b\n",
    "- Subsititute value of b, you get 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.grad means differentiating the equation wrt to x.\n",
    "- dy/dc = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "  1\n",
      " 20\n",
      " 50\n",
      "  0\n",
      "-50\n",
      "-20\n",
      " -1\n",
      "[torch.FloatTensor of size 7]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for_act = Variable(torch.Tensor([1,20,50,0,-50,-20,-1]))\n",
    "print(for_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_out = F.relu(for_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. 20. 50.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(relu_out.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bb89238358>]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bb89b1d668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(for_act.data.numpy(), relu_out.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP.DESKTOP-UCJPQBV\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "soft_out = F.softmax(for_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.2428857e-22, 9.3576229e-14, 1.0000000e+00, 1.9287499e-22,\n",
       "       3.7835059e-44, 3.9754500e-31, 7.0954744e-23], dtype=float32)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_out.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_out = F.sigmoid(for_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.3105860e-01, 1.0000000e+00, 1.0000000e+00, 5.0000000e-01,\n",
       "       1.9287499e-22, 2.0611537e-09, 2.6894143e-01], dtype=float32)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_out.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TanH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "tan_out = F.tanh(for_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7615942,  1.       ,  1.       ,  0.       , -1.       ,\n",
       "       -1.       , -0.7615942], dtype=float32)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tan_out.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In tutorial 2, I will explain Linear, logistic regression in two different methods\n",
    "### In tutorial 3, I will explain about the Neural Networks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
